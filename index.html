---
layout: base
---

<div class="landing">
  <div class="landing-callout">
      <div class="landing-intro">
          <div class="mobile-photo"></div>
          <h1>Tommy Truong</h1>
          <p>
              <span>UC San Diego Computer Engineering graduate.</span>
              <span>Voracious appetite for software development and data science.</span>
          </p>
      </div>
      <div class="landing-actions">
          <a class="landing-action" href="{{ site.baseurl }}/blog">
              <span class="icon-book"></span>
          </a>
          <!-- <a class="landing-action" href="assets/docs/TommyTruongResume.pdf"> -->
          <a class="landing-action" href="{{ site.baseurl }}/assets/docs/TommyTruongResume.pdf">
              <span class="icon-profile"></span>
          </a>
          <a class="landing-action" href="https://www.linkedin.com/in/ttthao/">
              <span class="icon-linkedin"></span>
          </a>
          <a class="landing-action" href="mailto:tttruong701@gmail.com">
              <span class="icon-mail"></span>
          </a>
      </div>
  </div>
</div>

<br>
<br>

<div class="container">
    <div class="section" id="work_experience">
        <div class="row center">
            <h3 class="header purple-text col s12">Work Experience</h3>
        </div>

        <div class="row">
            <div class="col s12 m6">
                <div class="card">
                    <div class="card-image">
                        <img class="activator" src="images/rdi.png">
                    </div>
                    <div class="card-content">
                        <span class="card-title activator grey-text text-darken-4">Software Engineering Intern<i class="material-icons right">more_vert</i></span>
                        <p>June 2017 - Present</p>
                    </div>
                    <div class="card-reveal">
                        <span class="card-title grey-text text-darken-4">Red Door Interactive<i class="material-icons right">close</i></span>
                        <p>
                            I have been Red Door’s principal developer for Domo projects. Domo is a cloud analytics dashboard and business intelligence platform. 
                        </p>
                        <p>
                            I wrote an API wrapper around Domo’s Javascript Connector API that speeds up the development of data connectors currently unavailable in Domo’s appstore. I’ve created connectors for the Google My Business, Moz and SEMrush API. 
                        </p>
                        <p>
                            I developed a proof-of-concept interactive web app to visualize paid, earned and owned media budgets across the customer journey stages using AWS and Vue.js. I attended preliminary brainstorms, drafted the requirements and worked with a senior graphic designer and marketer to implement the user interface and back-end logic. 
                        </p>
                        <p>
                            Lastly, using Python and Jupyter notebooks, I analyzed and visualized basic statistical properties of a golf client’s consumer survey dataset to make inferences on wedge purchasing and fitting behaviors based on age and skill level. 
                        </p>
                    </div>
                </div>
            </div>

            <div class="col s12 m6">
                <div class="card">
                    <div class="card-image">
                        <img class="activator" src="images/cmrg.jpeg">
                    </div>
                    <div class="card-content">
                        <span class="card-title activator grey-text text-darken-4">Programmer and IT Assistant<i class="material-icons right">more_vert</i></span>
                        <p>May 2016 - September 2017</p>
                    </div>
                    <div class="card-reveal">
                        <span class="card-title grey-text text-darken-4">Cardiac Mechanics Research Group<i class="material-icons right">close</i></span>
                        <p>
                            I oversaw all local and remote laboratory backups from 3 servers totaling over 10 TB of data with Bash scripts using rsync. I contributed to the development of a Django CMS website to host distributions and content for cardiac modeling software Continuity, and provided IT support for issues in network connectivity and software troubleshooting. 
                        </p>
                        <p>
                            The website development was split between me and a teammate. I worked on creating Django models and view templates that streamlined the process of storing and categorizing lecture materials pertaining to Continuity, which either fell in the biomechanics or electrophysiology category. Lecture materials consisted of slides or notes, reading assignments and attachments. 
                        </p>
                        <p>
                            I created a feedback form that lives at the footer of every Continuity tutorial that collects anonymous ratings and comments, as well as managed the hosting of the website and the Postgres database on the lab’s Apache server.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <br>
    <br>

    <div class="section" id="project_experience">
        <div class="row center">
            <h3 class="header purple-text col s12">Projects</h3>
        </div>
        <div class="col s12 m6">
            <div class="card">
                <div class="card-image">
                    <img class="activator" src="images/tastebuds.png">
                    <span class="card-title activator grey-text text-darken-4">TasteBuds</span>
                </div>
                <div class="card-content">
                    <span class="card-title activator grey-text text-darken-4">TasteBuds serves personalized Yelp listings based on your genetic phenotypes.<i class="material-icons right">more_vert</i></span>
                    <p>SD Hacks, October 2017</p>
                </div>
                <div class="card-reveal">
                    <span class="card-title grey-text text-darken-4">TasteBuds<i class="material-icons right">close</i></span>
                    <p>TasteBuds was developed for SD Hacks 2017 at UCSD, where my team was nominated by Awakens to fully develop the application.</p>
                    <p>
                        I ideated this application and added the back-end infrastructure
                        to support the Yelp Search API that sent requests using a
                        user’s top categories outputted from our predictive model. 
                        I added an embedded Google Maps to display the Yelp search results.
                        To parse user genomic data, I used Awaken’s Genomic data parser API to to make 
                        OAuth-authenticated requests to retrieve phenotype data, 
                        which describes a user’s likelihood of liking or disliking
                        traits, flavors and other human characteristics. Also, I
                        guided my teammates through creation of the model and 
                        the initialization of the weights using Pandas and NumPy.
                    </p>
                    <p>Languages/Frameworks: <b>Flask, Python, HTML, CSS, Pandas, NumPy</b></p>
                    <p>APIs: <b>Yelp, Google Maps, GenomeLink</b></p>
                </div>
                <div class="card-action">
                    <a href="https://github.com/ttthao/TasteBuds">Github</a>
                    <a href="https://devpost.com/software/sdhacks17-cv8zli">DevPost</a>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col s12 m6">
                <div class="card">
                    <div class="card-image">
                        <img class="activator" src="images/cmrg_rnn.jpg">
                        <span class="card-title activator grey-text text-darken-4">Cardiac Dyssynchrony Classifier</span>
                    </div>
                    <div class="card-content">
                        <span class="card-title activator grey-text text-darken-4">TensorFlow LSTM recurrent neural network that classifies VCG simulations to a cardiac dyssynchrony range<i class="material-icons right">more_vert</i></span>
                        <p>September 2016 - January 2017</p>
                    </div>
                    <div class="card-reveal">
                        <span class="card-title grey-text text-darken-4">Cardiac Dyssynchrony Classifier<i class="material-icons right">close</i></span>
                        <p>
                            Before joining the lab, I started learning about machine learning from a Stanford Coursera course. I pitched a project to a postdoctoral researcher from the lab, and with a teammate, we tackled a classification problem using a recurrent neural network written in TensorFlow. 
                        </p>
                        <p>
                            We hypothesized that the vectorcardiogram could be a good predictor of the cardiac dyssynchrony index, which in theory could catch future cardiac arrhythmia by providing patients with preventative care sooner. 
                        </p>
                        <p>
                            A vectorcardiogram, or VCG, is a recording of the magnitude and direction of the total electrical forces generated by the heart over time. It is represented by a single vector with a moving head and a tail fixed at the origin. Since the VCG was treated as a sequence, each timestep can be viewed as one spatial position in time. So for every time t, we are given the (x, y, z) coordinates of the vector head.
                        </p>
                        <p>
                            Each VCG simulation maps to a dyssynchrony index. The dyssynchrony index is an indicator of a patient’s response to Cardiac Resynchronization Therapy (CRT), which is a process that resynchronizes the contractions of the heart’s to help the heart pump blood more efficiently. It is a scalar value that theoretically ranges from 0 to 1, but we were only concerned with the range from 0.5 to 1.
                        </p>
                        <p>
                            My teammate and I both worked on implementing the TensorFlow recurrent neural network. 
                        </p>
                        <p>
                            I ran several experiments to do a limited grid-search over the network’s hyperparameters, such as the number of hidden units, learning rate and weight initialization, and logged the training results. 
                        </p>
                        <p>
                            Through analyzing the logs, I was able to improve our model’s testing accuracy from 36% to 73% by selecting the optimal hyperparameters from the grid-search.
                        </p>
                        <p>
                            Also, I extended the iterator module that feeds batches of VCG simulation data to include data from patient 7 and 8 to expose the network to more data, proving our initial concerns were wrong.
                        </p>
                        <p>Languages/Frameworks: <b>Python, TensorFlow</b></p>
                    </div>
                    <div class="card-action">
                        <a href="https://github.com/ttthao/PredictDyssynchronyIndex">Github</a>
                    </div>
                </div>
            </div>
            <div class="col s12 m6">
                <div class="card">
                    <div class="card-image">
                        <img class="activator" src="images/cmrg_electro.png">
                        <span class="card-title activator white-text text-darken-4">Electrophysiology Animator</span>
                    </div>
                    <div class="card-content">
                        <span class="card-title activator grey-text text-darken-4">Electrophysiology animator renders the electrical activity of a patient-specific ventricular model.<i class="material-icons right">more_vert</i></span>
                        <p>June 2016 - September 2016</p>
                    </div>
                    <div class="card-reveal">
                        <span class="card-title grey-text text-darken-4">Electrophysiology Animator<i class="material-icons right">close</i></span>
                        <p>
                            I worked with a teammate and postdoctoral researcher 
                            to develop a Python script
                            to distributedly render and animate the electrical
                            activation of a patient-specific cardiac model using
                            Blender API. This was the first time the rendering 
                            of a patient-specific model was ever done (at the time!).
                        </p>
                        <p>
                            Blender indexes vertices of a mesh in respect to the
                            entire model and to each face of the model. For 
                            example, a cube in Blender has 8 global vertices,
                            and has 24 local vertices (each of the 6 faces has 4
                            vertices). The voltage solution mesh, the NumPy array
                            describing the color of each vertex in the model 
                            during an electrical activation, indexes global 
                            vertices. While the vertex color layer, a Blender 
                            data structure that color describes the color of 
                            every vertex in a mesh, indexes local vertices. 
                        </p>
                        <p>
                            I wrote the Python script to map the global vertices
                            of the voltage solution mesh to the local vertices
                            of the cardiac model. Also, I scripted the the Blender 
                            camera and environment setup for the animation. 
                        </p>
                        <p>
                            I targeted the surface vertices of the cardiac model
                            in Blender’s GUI, and filtered the vertices that had
                            the “surface” tag during the mapping to ignore inner
                            vertices during rendering. I reduced the rendering
                            time from 4 to 2 days.
                        </p>
                        <p>
                            To further optimize the script, I distributed the rendering
                            by writing a Bash script to submit remote Unix jobs
                            on the San Diego Super Computer GPU clusters that
                            rendered intervals of the animation, reducing the
                            overall rendering time by 80%. The rendering process
                            time dropped to 2-3 hours.
                        </p>
                        <p>Languages/Frameworks: <b>Python, NumPy</b></p>
                        <p>APIs: <b>Blender</b></p>
                    </div>
                    <div class="card-action">
                        <a href="https://github.com/ttthao/AnimateCardiacEP">Github</a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
